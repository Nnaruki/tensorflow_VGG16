{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "allied-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "oriental-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#二個以上のデータが必須"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "rotary-knight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n02808304', 'bath_towel', 0.5132788)\n",
      "('n02093647', 'Bedlington_terrier', 0.2106744)\n",
      "('n02096585', 'Boston_bull', 0.20385276)\n",
      "('n04033995', 'quilt', 0.13576117)\n",
      "('n02113186', 'Cardigan', 0.22330862)\n",
      "('n02808304', 'bath_towel', 0.39184946)\n",
      "('n01883070', 'wombat', 0.4659271)\n",
      "('n02342885', 'hamster', 0.37108)\n",
      "('n02123159', 'tiger_cat', 0.11824806)\n",
      "('n02123045', 'tabby', 0.524172)\n",
      "('n02123045', 'tabby', 0.21434937)\n",
      "('n02124075', 'Egyptian_cat', 0.1857429)\n",
      "('n02808304', 'bath_towel', 0.25209907)\n",
      "('n03958227', 'plastic_bag', 0.17108724)\n",
      "('n02123045', 'tabby', 0.32466936)\n",
      "('n02124075', 'Egyptian_cat', 0.32373947)\n",
      "('n02123045', 'tabby', 0.21119972)\n",
      "('n02124075', 'Egyptian_cat', 0.6907798)\n",
      "('n02123045', 'tabby', 0.5944198)\n",
      "('n04277352', 'spindle', 0.15456331)\n",
      "('n01817953', 'African_grey', 0.33562785)\n",
      "('n02113978', 'Mexican_hairless', 0.14990638)\n",
      "('n02124075', 'Egyptian_cat', 0.7122979)\n",
      "('n04399382', 'teddy', 0.29544878)\n",
      "('n02124075', 'Egyptian_cat', 0.2608785)\n",
      "('n02123045', 'tabby', 0.38280317)\n",
      "('n02123597', 'Siamese_cat', 0.5641674)\n",
      "('n01817953', 'African_grey', 0.4009157)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import load_img\n",
    "import time\n",
    "img_1= load_img('noda_cat/1/IMG_3026.JPG',target_size=(224,224))\n",
    "img_2= load_img('noda_cat/1/IMG_3030.JPG',target_size=(224,224))\n",
    "img_3= load_img('noda_cat/1/IMG_3031.JPG',target_size=(224,224))\n",
    "img_4= load_img('noda_cat/1/IMG_3037.JPG',target_size=(224,224))\n",
    "img_5= load_img('noda_cat/1/IMG_3048.JPG',target_size=(224,224))\n",
    "img_6= load_img('noda_cat/1/cat1.png',target_size=(224,224))\n",
    "\n",
    "number = 0\n",
    "img={}\n",
    "arr={}\n",
    "\n",
    "for i in range(28):\n",
    "    img[number] = load_img('noda_cat/sum/IMG_30{0}.JPG'.format(number+20),target_size=(224,224))\n",
    "    \n",
    "    arr[number]=img_to_array(img[number])\n",
    "    \n",
    "    arr[number] = preprocess_input(arr[number])\n",
    "    number+=1\n",
    "    \n",
    "arr_input = np.stack([arr[0],arr[1],arr[2],arr[3],arr[4],arr[5],arr[6],arr[7],arr[8],arr[9],arr[10],arr[11],arr[12],arr[13],arr[14],arr[15],arr[16],arr[17],arr[18],arr[19],arr[20],arr[21],arr[22],arr[23],arr[24],arr[25],arr[26],arr[27]])\n",
    "probs = model.predict(arr_input)\n",
    "results = decode_predictions(probs)\n",
    "\n",
    "x=0\n",
    "for i in range(28):\n",
    "    print(results[x][0])\n",
    "    x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "medieval-sequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n01883070', 'wombat', 0.4659271),\n",
       " ('n01877812', 'wallaby', 0.18015793),\n",
       " ('n02091467', 'Norwegian_elkhound', 0.06073136),\n",
       " ('n01882714', 'koala', 0.050029293),\n",
       " ('n03794056', 'mousetrap', 0.028420351)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "appropriate-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import img_to_array\n",
    "arr_1=img_to_array(img_1)\n",
    "arr_2=img_to_array(img_2)\n",
    "arr_3=img_to_array(img_3)\n",
    "arr_4=img_to_array(img_4)\n",
    "arr_5=img_to_array(img_5)\n",
    "arr_6=img_to_array(img_6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-while",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promotional-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
    "arr_1 = preprocess_input(arr_1)\n",
    "arr_2 = preprocess_input(arr_2)\n",
    "arr_3 = preprocess_input(arr_3)\n",
    "arr_4 = preprocess_input(arr_4)\n",
    "arr_5 = preprocess_input(arr_5)\n",
    "arr_6 = preprocess_input(arr_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "rolled-clinic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr_input = np.stack([arr_1,arr_2,arr_3,arr_4,arr_5,arr_6])\n",
    "arr_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hearing-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict(arr_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "growing-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications.vgg16 import decode_predictions\n",
    "results = decode_predictions(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "rubber-factor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n02123045', 'tabby', 0.21434957)\n",
      "('n02124075', 'Egyptian_cat', 0.18574296)\n",
      "('n02124075', 'Egyptian_cat', 0.6907794)\n",
      "('n02124075', 'Egyptian_cat', 0.19991513)\n",
      "('n02123045', 'tabby', 0.6588691)\n",
      "0.4478834203887874\n",
      "0.5521165796112125\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "total=0\n",
    "tabby=0\n",
    "Egypt=0\n",
    "for i in range(5):\n",
    "    x += 1\n",
    "    total +=results[x][0][2]\n",
    "    print(results[x][0])\n",
    "    if results[x][0][1] == \"tabby\":\n",
    "        tabby += results[x][0][2]\n",
    "    elif results[x][0][1] == \"Egyptian_cat\":\n",
    "        Egypt += results[x][0][2]\n",
    "    \n",
    "print(tabby/total)   \n",
    "print(Egypt/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-roots",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-occasions",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
